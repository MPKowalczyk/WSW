\section{Koncepcja proponowanego rozwiązania}
\label{sub:koncepcja}

Pierwsza część pracy polegała na stworzeniu bazy danych, na których następnie można było uczyć sieć neuronową. Jak zostało wspomniane w sekcji \ref{sub:analiza}, około 10\% danych dostarczonych przez autorów bazy \textit{MNIST-DVS} w źródle \cite{MNIST_DVS} zostało wykorzystanych w~niniejszej pracy. Ponieważ rozważano dwie koncepcje, dane zostały przygotowane do realizacji obu w podobny sposób, jednak na końcu zostały zapisane w innej formie, co zostanie omówione w późniejszej części rozdziału.

Dane zostały wybrane w sposób losowy, odrzucono tylko początkowe wartości, które mogłyby być nieco zaszumione i wprowadzać niepotrzebne rozbieżności. Mając już tak przygotowany zestaw danych, zauważono pewną powtarzalność w przedstawianiu zdarzeń. Otóż zdarzenia przedstawiające zmianę położenia liczby znajdują się w podobnym miejscu (jak już zostało wspomniane, nie cały zestaw danych, czyli zbiór zdarzeń został wzięty pod uwagę). Dzięki temu można było znacząco zmniejszyć wymiary danych wejściowych do rozmiaru 40 $\times$ 40. Taki zabieg przyspieszył i tak już zaawansowane obliczenia.
W dalszej kolejności stworzono tablicę wartości boolean o rozmiarze 40 $\times$ 40 i~przepisano tam wartość 1 w miejscach, gdzie wystąpiły zdarzenia. W ten sposób powstało 94 490 takich tablic (po około 10 000 na jedną cyfrę). Braki wynikają z błędów twórców bazy \textit{MNIST-DVS}, ale zostały wyeliminowane w procesie działania zaprezentowanego algorytmu. Ponieważ uczenie sieci neuronowej zastosowanej w omawianej metodzie następowało z nauczycielem, potrzebne było stworzenie macierzy wyjść. Macierz do tego utworzona miała tyle wierszy, ile tablic wejściowych, zaś kolumn tyle co cyfr, czyli 10. Wartość 1 w danej kolumnie informowała tu z jaką cyfrą mamy w tym przypadku do czynienia - numer kolumny wskazywał cyfrę pomniejszoną o jeden (pierwsza kolumna dla 0).  

Uczenie sieci odbyło się równolegle na dwa sposoby. Pierwszy wymagał przedstawienia danych w postaci wierszowej. Stworzono więc macierz mającą tyle wierszy, ile danych wejściowych i tyle kolumn, ile wartości przypadało na każdą daną, czyli 1600. Drugi sposób pozwalał na stworzenie tablicy celek. Dane wejściowe były przedstawione w taki sposób, że każda celka była tablicą 40 $\times$ 40, czyli jedną daną. Etykiety stworzono bazując na macierzy wyjść. Każda celka przestawiała tu wektor o rozmiarze 10, w którym na odpowiednim miejscu, oznaczającym daną cyfrę, znajdowała się wartość 1. Synchronizację otrzymano poprzez numer celki w danych wejściowych odpowiadał numerowi celki w tablicy wyjściowej zawierającej etykiety.

Pierwsze podejście uczenia sieci zakładało użycie GUI programu \textit{MATLAB - Neural Network Toolbox}, a dokładnie jego części odpowiedzialnej za rozpoznawanie wzorców i~klasyfikację danych - \textit{nprtool}. Po wprowadzeniu tu wartości wejściowych i etykiet, ustala się liczbę neuronów ukrytych i można już przejść do nauki sieci neuronowej. \textit{MATLAB} sam ustala tutaj liczbę danych potrzebnych do uczenia, walidacji i testowania. Program używa tutaj sieci neuronowej z użyciem algorytmu wstecznej propagacji błędów (z ang. \textit{backpropagation}). Algorytm uczenia kończy działanie po udanej sześciokrotnej walidacji. Wyniki testowania można zaobserwować na stworzonych przez GUI statystykach.

Drugie podejście zostało stworzone po to, aby móc zastosować głęboką sieć neuronową. Uczenie tej sieci odbywa się używając macierzy wejściowej i etykiet wyjściowych, czyli jest to uczenie z nauczycielem. Dodatkowo wprowadzone parametry pozwalają na zastosowanie równoległości obliczeń na wielu rdzeniach oraz użycie procesora graficznego GPU. Zastosowanie jest uzasadnione ze względu na dużą liczbę danych wejściowych, co zostało omówione w sekcji \ref{sub:analiza}. To wszystko pozwala na przyspieszenie tego etapu uczenia. Uzasadnione jest tu użycie autoenkodera w celu dodania warstw ukrytych. Użyto tutaj GPU dodając odpowiedni parametr w funkcji \textit{trainAutoencoder}, ustalona została też maksymalna liczba epok. W celu stworzenia pełnej sieci, dodano warstwę wyjściową. Uwzględniając fakt, że jest to problem klasyfikacyjny, stworzono funkcję aktywacji typu \textit{softmax}. Tak nauczoną sieć poddano testowaniu. Wyniki uzyskane nieco różnią się od wyników uzyskanych w podejściu wcześniejszym, co zostanie omówione w sekcji \ref{sub:testowanie}.

% schemat blokowy